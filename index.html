<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VR Audio Visualizer + Video Wall</title>
    <!-- A-Frame Library -->
    <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>
    <style>
        body { margin: 0; }
        canvas { width: 100%; height: 100%; }
    </style>
</head>
<body>
    <a-scene id="main-scene" background="color: #000">
        <!-- 
          ============================================================
          ASSETS MANAGEMENT
          Pre-loading assets like videos is crucial for performance.
          The video is given an ID and referenced by other entities.
          ============================================================
        -->
        <a-assets>
            <!-- The video file, expected to be in the same directory. -->
            <video id="my-video" src="video.mp4" loop="true" preload="auto" crossOrigin="anonymous"></video>
        </a-assets>

        <!-- Camera and Cursor -->
        <a-camera>
            <a-cursor></a-cursor>
        </a-camera>

        <!-- 
          THE CUBE ROOM - "SHADES OF BLUE" VIBE
        -->
        <a-plane position="0 -5 0" rotation="-90 0 0" width="10" height="10" color="#001f3f"></a-plane>
        <a-plane position="0 5 0" rotation="90 0 0" width="10" height="10" color="#7FDBFF"></a-plane>
        <a-plane position="0 0 5" rotation="0 180 0" width="10" height="10" color="#0074D9"></a-plane>
        <a-plane position="5 0 0" rotation="0 -90 0" width="10" height="10" color="#00BFFF"></a-plane>
        
        <!-- 
          NEW FEATURE: VIDEO WALL
          This plane uses the preloaded video from <a-assets> as its texture.
          It has an ID so we can target it with JavaScript for play/pause controls.
        -->
        <a-plane id="video-wall" position="-5 0 0" rotation="0 90 0" width="10" height="10" src="#my-video" color="#39CCCC">
            <!-- A simple "Play" icon to indicate interactivity -->
            <a-text id="play-icon" value="â–º" align="center" width="15" color="white"></a-text>
        </a-plane>

        <!-- Front Wall (Visualizer Host) -->
        <a-plane id="visualizer-wall" position="0 0 -5" width="10" height="10" color="#001020"></a-plane>
        <a-entity id="visualizer-bars-container" position="0 0 -4.95"></a-entity>

        <!-- UI Elements -->
        <a-entity id="start-button" position="0 1.6 -3" 
                  geometry="primitive: sphere; radius: 0.3;" 
                  material="color: #FFDC00; shader: flat;">
            <a-text value="Start Visualizer" align="center" position="0 0.5 0" width="3" color="black"></a-text>
        </a-entity>
        <a-text id="status-text" value="" align="center" position="0 2.5 -4" color="white" width="6" visible="false"></a-text>
    </a-scene>

    <script>
    document.addEventListener('DOMContentLoaded', () => {
        
        // ============================================================
        // VARIABLE DECLARATIONS
        // ============================================================
        const scene = document.getElementById('main-scene');
        const startButton = document.getElementById('start-button');
        const statusText = document.getElementById('status-text');
        
        // Visualizer variables
        const barsContainer = document.getElementById('visualizer-bars-container');
        let visualizerBars = [];
        const NUM_BARS = 32;

        // Video variables
        const videoWall = document.getElementById('video-wall');
        const videoEl = document.getElementById('my-video');
        const playIcon = document.getElementById('play-icon');
        
        // Web Audio API variables
        let audioContext;
        let analyser;
        let microphone;
        let dataArray;
        let isAudioInitialized = false;

        // ============================================================
        // VISUALIZER SETUP (No changes from previous version)
        // ============================================================
        function createVisualizerBars() {
            const totalWidth = 9.8; 
            const barWidth = totalWidth / NUM_BARS;
            const effectiveBarWidth = barWidth - (barWidth * 0.15);
            for (let i = 0; i < NUM_BARS; i++) {
                const bar = document.createElement('a-box');
                const xPosition = -totalWidth / 2 + i * barWidth + barWidth / 2;
                bar.setAttribute('position', `${xPosition} 0 0`);
                bar.setAttribute('width', effectiveBarWidth);
                bar.setAttribute('depth', 0.2);
                bar.setAttribute('height', 0.1);
                bar.setAttribute('material', { shader: 'flat', color: '#FFA500' });
                barsContainer.appendChild(bar);
                visualizerBars.push(bar);
            }
        }

        // ============================================================
        // WEB AUDIO API INITIALIZATION & BUG FIXING
        // ============================================================
        async function initAudio() {
            // If already initialized, do nothing.
            if (isAudioInitialized) return;

            console.log('Attempting to start audio...');
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
                
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                microphone = audioContext.createMediaStreamSource(stream);
                microphone.connect(analyser);

                const bufferLength = analyser.frequencyBinCount;
                dataArray = new Uint8Array(bufferLength);
                
                startButton.setAttribute('visible', 'false');
                statusText.setAttribute('value', 'Microphone Connected!');
                statusText.setAttribute('visible', 'true');
                setTimeout(() => statusText.setAttribute('visible', 'false'), 2000);

                isAudioInitialized = true;
                updateVisualizer();

            } catch (err) {
                console.error('Error accessing microphone:', err);
                statusText.setAttribute('value', 'Microphone access denied.');
                statusText.setAttribute('visible', 'true');
                startButton.setAttribute('visible', 'false');
            }
        }

        /**
         * BUG FIX ATTEMPT: This function is called when the user clicks the start button
         * OR when they enter VR mode. It checks if the audio context is "suspended"
         * and tries to resume it. This is a common requirement for WebXR.
         */
        function resumeAudioContext() {
            if (audioContext && audioContext.state === 'suspended') {
                console.log('AudioContext is suspended. Attempting to resume...');
                audioContext.resume().then(() => {
                    console.log('AudioContext resumed successfully.');
                }).catch(e => console.error('Failed to resume AudioContext:', e));
            }
        }

        // ============================================================
        // VIDEO WALL PLAYBACK CONTROL
        // ============================================================
        function toggleVideoPlayback() {
            if (!videoEl) return;

            if (videoEl.paused) {
                videoEl.play();
                playIcon.setAttribute('visible', 'false'); // Hide play icon when playing
            } else {
                videoEl.pause();
                playIcon.setAttribute('visible', 'true'); // Show play icon when paused
            }
        }

        // ============================================================
        // VISUALIZER ANIMATION LOOP
        // ============================================================
        function updateVisualizer() {
            if (!isAudioInitialized) return;

            requestAnimationFrame(updateVisualizer);
            analyser.getByteFrequencyData(dataArray);

            for (let i = 0; i < NUM_BARS; i++) {
                const sliceWidth = Math.floor(dataArray.length / NUM_BARS);
                let sliceStart = i * sliceWidth;
                let slice = dataArray.slice(sliceStart, sliceStart + sliceWidth);
                let averageVolume = slice.reduce((a, b) => a + b, 0) / slice.length;
                const height = (averageVolume / 255) * 9.5 + 0.1;
                
                const bar = visualizerBars[i];
                if (bar) {
                    bar.setAttribute('height', height);
                    bar.setAttribute('position', { y: height / 2 - 5, x: bar.getAttribute('position').x, z: 0 });
                }
            }
        }

        // ============================================================
        // EVENT LISTENERS & INITIALIZATION
        // ============================================================
        createVisualizerBars();
        
        // Listener for the audio start button
        startButton.addEventListener('click', initAudio);

        // Listener for the video wall click
        videoWall.addEventListener('click', toggleVideoPlayback);

        // BUG FIX LISTENER: Listen for the 'enter-vr' event on the scene.
        // When the user enters immersive mode, we explicitly try to resume the audio context.
        scene.addEventListener('enter-vr', () => {
            console.log("Entered VR mode. Checking audio context state.");
            resumeAudioContext();
        });
    });
    </script>
</body>
</html>
